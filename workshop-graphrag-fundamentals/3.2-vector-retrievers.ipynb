{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa5eb02",
   "metadata": {},
   "source": [
    "# Vector & Relationships\n",
    "\n",
    "## Installation\n",
    "\n",
    "This notebook requires the following dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install neo4j-graphrag python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af3348",
   "metadata": {},
   "source": [
    "## Connecting to Neo4j\n",
    "\n",
    "The following cell creates an instance of the Neo4j Python Driver that the retrievers require to connect to the database.  The driver is created with environment variables set in your `.env` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "from os import getenv\n",
    "\n",
    "NEO4J_URL = getenv(\"NEO4J_URI\") or \"neo4j://localhost:7687\"\n",
    "NEO4J_USERNAME = getenv(\"NEO4J_USERNAME\") or \"neo4j\"\n",
    "NEO4J_PASSWORD = getenv(\"NEO4J_PASSWORD\") or \"neoneoneo\"\n",
    "NEO4J_DATABASE = getenv(\"NEO4J_DATABASE\") or \"neo4j\"\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    NEO4J_URL,\n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    ")\n",
    "\n",
    "driver.verify_connectivity() # Throws an error if the connection is not successful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94398e7a",
   "metadata": {},
   "source": [
    "## Plain vector search\n",
    "\n",
    "A vector index already exists called `chunkEmbeddings`.  You can [create your own using the `create_vector_index` function](https://github.com/neo4j/neo4j-graphrag-python?tab=readme-ov-file#creating-a-vector-index) or [populate an existing index using the `upsert_vectors` function](https://github.com/neo4j/neo4j-graphrag-python?tab=readme-ov-file#populating-a-vector-index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433cada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"chunkEmbeddings\"\n",
    "\n",
    "from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "\n",
    "# Create an Embedder object\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = VectorRetriever(\n",
    "    driver,\n",
    "    neo4j_database=NEO4J_DATABASE,\n",
    "    index_name=INDEX_NAME,\n",
    "    embedder=embedder\n",
    ")\n",
    "\n",
    "# Instantiate the LLM\n",
    "llm = OpenAILLM(model_name=\"gpt-4o\", model_params={\"temperature\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dec322",
   "metadata": {},
   "source": [
    "The `GraphRAG` class creates a retrieval pipeline that accepts a user input, uses a retriever to fetch the context, and uses an LLM to generate an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.generation import GraphRAG\n",
    "\n",
    "# Instantiate the RAG pipeline\n",
    "rag = GraphRAG(\n",
    "    retriever=retriever,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Query the graph\n",
    "query = \"What are the top risk factors that Apple faces? Cite your sources.\"\n",
    "\n",
    "vector_response = rag.search(query_text=query, return_context=True, retriever_config={\"top_k\": 5})\n",
    "\n",
    "print(vector_response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea47be2",
   "metadata": {},
   "source": [
    "## Adding context via relationships\n",
    "\n",
    "The above pipeline will produce a generic, non-deterministic answer.  Adding relationships to the query will provide a deterministic answer based on the contents of the knowledge graph.  We do this with the `VectorCypherRetriever` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d277103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import VectorCypherRetriever\n",
    "\n",
    "# --- VectorCypherRetriever Example: Detailed Search with Context\n",
    "detail_context_query = \"\"\"\n",
    "MATCH (node)-[:FROM_DOCUMENT]-(doc:Document)-[:FILED]-(company:Company)-[:FACES_RISK]->(risk:RiskFactor)\n",
    "RETURN company.name AS company, collect(DISTINCT risk.name) AS risks, node.text AS context\n",
    "\"\"\"\n",
    "\n",
    "vector_cypher_retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name='chunkEmbeddings',\n",
    "    embedder=embedder,\n",
    "    retrieval_query=detail_context_query\n",
    ")\n",
    "\n",
    "rag = GraphRAG(retriever=vector_cypher_retriever, llm=llm)\n",
    "\n",
    "query = \"What are the top risk factors that Apple faces? Cite your sources. \"\n",
    "\n",
    "vector_cypher_response = rag.search(query_text=query, return_context=True, retriever_config={\"top_k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vector_cypher_response.answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in vector_cypher_response.retriever_result.items:\n",
    "    print(item.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b25e8",
   "metadata": {},
   "source": [
    "## Evaluating the responses\n",
    "\n",
    "You can use **Noise Sensitivity** to measures the amount of irrelevant information, or noise, in the retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0728e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ragas langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901131e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "from ragas import evaluate, EvaluationDataset\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextPrecisionWithReference, LLMContextPrecisionWithoutReference, NoiseSensitivity\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "context_precision = LLMContextPrecisionWithReference(llm=evaluator_llm)\n",
    "noise_sensitivity = NoiseSensitivity(llm=evaluator_llm, mode=\"irrelevant\")\n",
    "\n",
    "metrics = [\n",
    "    context_precision,\n",
    "    noise_sensitivity\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ab96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth/reference data from the database\n",
    "reference = driver.execute_query(\n",
    "    \"match (c:Company {name: 'APPLE INC'})-[:FACES_RISK]->(r) RETURN r.name AS risk ORDER BY risk\",\n",
    "    database_=NEO4J_DATABASE,\n",
    "    result_transformer_=lambda result: \", \".join([row['risk'] for row in result])\n",
    ")\n",
    "\n",
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa55c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample\n",
    "\n",
    "# Ensure that each retrieved context is a string and not a sequence/object\n",
    "def flatten_and_stringify_contexts(contexts):\n",
    "    flat_contexts = []\n",
    "    for item in contexts:\n",
    "        # If item.content is a list or sequence, join its elements; else, str it\n",
    "        content = getattr(item, \"content\", item)\n",
    "        if isinstance(content, (list, tuple)):\n",
    "            flat_contexts.append(\" \".join(str(x) for x in content))\n",
    "        else:\n",
    "            flat_contexts.append(str(content))\n",
    "    return flat_contexts\n",
    "\n",
    "vector_contexts = flatten_and_stringify_contexts(vector_response.retriever_result.items)\n",
    "cypher_contexts = flatten_and_stringify_contexts(vector_cypher_response.retriever_result.items)\n",
    "\n",
    "vector_result = SingleTurnSample(\n",
    "    user_input=query,\n",
    "    reference=reference,\n",
    "    retrieved_contexts=vector_contexts,\n",
    "    response=vector_response.answer,\n",
    ")\n",
    "\n",
    "# Ensure cypher_contexts is a flat list of strings (not a list of lists or sequences)\n",
    "flat_cypher_contexts = []\n",
    "for ctx in cypher_contexts:\n",
    "    if isinstance(ctx, (list, tuple)):\n",
    "        flat_cypher_contexts.append(\" \".join(str(x) for x in ctx))\n",
    "    else:\n",
    "        flat_cypher_contexts.append(str(ctx))\n",
    "\n",
    "cypher_result = SingleTurnSample(\n",
    "    user_input=query,\n",
    "    reference=reference,\n",
    "    retrieved_contexts=flat_cypher_contexts,\n",
    "    response=vector_cypher_response.answer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15586965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vector:\")\n",
    "for metric in metrics:\n",
    "    try:\n",
    "        print(metric.name, \"vector\", await metric.single_turn_ascore(vector_result))\n",
    "    except ValueError as e:\n",
    "        print(metric.name, \"vector\", e)\n",
    "\n",
    "\n",
    "print(\"\\nVector + Relationships:\")\n",
    "for metric in metrics:\n",
    "    try:\n",
    "        print(metric.name, \"cypher\", await metric.single_turn_ascore(cypher_result))\n",
    "    except ValueError as e:\n",
    "        print(metric.name, \"cypher\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
